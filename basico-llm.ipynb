{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RumqOCYbYDid","executionInfo":{"status":"ok","timestamp":1741979533750,"user_tz":180,"elapsed":121600,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}},"outputId":"993a640f-8c7b-4c78-a64a-85d829fee8a9","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n","Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.6.0+cu124)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}],"source":["#redirecionamento para o torch é importante para instalar bibliotecas de\n","#otimização necessárias para parte do treino da LLM\n","!pip install transformers[torch]"]},{"cell_type":"code","source":["#texto que será usado para treinamento\n","!wget -O ./sample_data/jcs.txt https://raw.githubusercontent.com/graciellenjose/llm-estudos/refs/heads/main/jcs.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnvUbOliYFvL","executionInfo":{"status":"ok","timestamp":1741979534163,"user_tz":180,"elapsed":411,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}},"outputId":"aefe7bf6-50ea-453d-b280-e1ffd07b8ec0","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-03-14 19:12:13--  https://raw.githubusercontent.com/graciellenjose/llm-estudos/refs/heads/main/jcs.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 36624 (36K) [text/plain]\n","Saving to: ‘./sample_data/jcs.txt’\n","\n","./sample_data/jcs.t 100%[===================>]  35.77K  --.-KB/s    in 0.002s  \n","\n","2025-03-14 19:12:14 (22.6 MB/s) - ‘./sample_data/jcs.txt’ saved [36624/36624]\n","\n"]}]},{"cell_type":"code","source":["#definindo de onde virá o texto\n","from os.path import sameopenfile\n","PATH = './sample_data/'\n","texto_treino = 'jcs.txt'"],"metadata":{"id":"iXxLgS5G-ymD","executionInfo":{"status":"ok","timestamp":1741979547948,"user_tz":180,"elapsed":4,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#byte level conta as frequências de pares de tokens\n","#e soma os ids\n","from tokenizers import ByteLevelBPETokenizer\n","\n","tokenizer = ByteLevelBPETokenizer()\n","\n","#files - arquivo(s) de treino\n","#vocab_size - quantidade de espaço para armazenamento de possibilidades\n","#min_frequency - número de ocorrências dos pares\n","#special_tokens - caracteres especiais\n","tokenizer.train(files=[PATH+texto_treino], vocab_size=52_000, min_frequency=2, special_tokens=[\n","    \"<s>\", #começo da linha\n","    \"<pad>\", #preenchimento de espaços em brancos\n","    \"</s>\", #final de frase\n","    \"<unk>\", #caractere desconhecido\n","    \"<mask>\", #caractere para predição\n","])"],"metadata":{"id":"VpcVzUpz_LgH","executionInfo":{"status":"ok","timestamp":1741979549229,"user_tz":180,"elapsed":144,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["tokenizer.encode('Uma frase é um enunciado falado ou escrito que apresenta um sentido completo.').ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhkHGoJ3BLTh","executionInfo":{"status":"ok","timestamp":1741979554116,"user_tz":180,"elapsed":5,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}},"outputId":"78ceb506-bbe2-45fc-ecd1-e8fc8202ff70"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[57,\n"," 81,\n"," 69,\n"," 616,\n"," 367,\n"," 73,\n"," 225,\n"," 132,\n"," 107,\n"," 225,\n"," 89,\n"," 81,\n"," 225,\n"," 310,\n"," 548,\n"," 71,\n"," 77,\n"," 377,\n"," 83,\n"," 285,\n"," 385,\n"," 377,\n"," 83,\n"," 225,\n"," 263,\n"," 225,\n"," 282,\n"," 71,\n"," 86,\n"," 298,\n"," 83,\n"," 853,\n"," 73,\n"," 266,\n"," 84,\n"," 274,\n"," 87,\n"," 503,\n"," 69,\n"," 225,\n"," 89,\n"," 81,\n"," 272,\n"," 503,\n"," 368,\n"," 83,\n"," 712,\n"," 84,\n"," 80,\n"," 315,\n"," 83,\n"," 18]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#salvar tokenização\n","!rm -r ./sample_data/RAW_MODEL\n","!mkdir ./sample_data/RAW_MODEL\n","tokenizer.save_model(PATH+'RAW_MODEL')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K15-szggCbbT","executionInfo":{"status":"ok","timestamp":1741979559988,"user_tz":180,"elapsed":218,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}},"outputId":"18aa4299-0599-4b9d-8926-7ff901128f24"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove './sample_data/RAW_MODEL': No such file or directory\n"]},{"output_type":"execute_result","data":{"text/plain":["['./sample_data/RAW_MODEL/vocab.json', './sample_data/RAW_MODEL/merges.txt']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#modelo de tokenizer BERT\n","#separar parte de treino da parte de processamento\n","\n","#from tokenizers.implementations import ByteLevelBPETokenizer\n","#from tokenizers.processors import BertProcessing\n","\n","#tokenizer = ByteLevelBPETokenizer(\n","#    PATH+'RAW_MODEL'+\"/vocab.json\",\n","#    PATH+'RAW_MODEL'+\"/merges.txt\",\n","#)\n","\n","#tokenizer._tokenizer.post_processor = BertProcessing(\n","    #identifica que o <s> e </s> do tokenizer é o mesmo do vocabulário.\n","    #serve para deiferenciar frases que já foram processadas de frases que não\n","    #foram\n","#    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n","#    (\"<s>\", tokenizer.token_to_id(\"<s>\"))\n","#)\n","\n","#tokenizer.enable_truncation(max_length=512)"],"metadata":{"id":"5siX6xBBFmkr","executionInfo":{"status":"ok","timestamp":1741979562289,"user_tz":180,"elapsed":43,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#o modelo RoBERTa é uma melhoria do BERT que permite que a utilização em\n","#dados reais seja mais rápida. É otimizada para menores quantidades de dados e\n","#máquinas com menos recursos\n","from transformers import RobertaTokenizer\n","\n","tokenizer = RobertaTokenizer.from_pretrained(PATH+'RAW_MODEL', max_length=512)\n","#é pre_trained, por o vocabulário com os merges já existe"],"metadata":{"id":"dtc3y6f4IpVd","executionInfo":{"status":"ok","timestamp":1741979581952,"user_tz":180,"elapsed":15240,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#Transformer\n","from transformers import RobertaConfig\n","\n","config = RobertaConfig(\n","    vocab_size=52_000, #quantidade do vocabulário\n","    max_position_embeddings=512, #quantidade de embeddings do vetor\n","    num_attention_heads=12, #garantem que o contexto seja levado em conta\n","    num_hidden_layers=6,\n","    type_vocab_size=1,\n",")"],"metadata":{"id":"on0HElupK_jM","executionInfo":{"status":"ok","timestamp":1741979585068,"user_tz":180,"elapsed":14,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!echo \".ignoreme\" > .gitignore\n","from google.colab import userdata\n","\n","username = userdata.get('username')\n","useremail = userdata.get('useremail')\n","password = userdata.get('password')\n","token = userdata.get('token')\n","\n","!git config --global user.name {username}\n","!git config --global user.email {useremail}\n","!git config --global user.password {password}"],"metadata":{"id":"1CQcIEmU36kr","executionInfo":{"status":"ok","timestamp":1741979620610,"user_tz":180,"elapsed":2477,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!echo \".ignoreme\" > .gitignore\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"collapsed":true,"id":"Igzu9XL76VZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!echo \".ignoreme\" > .gitignore\n","%cd /content/drive/MyDrive/Colab\\ Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kX2s9UDx7FBX","executionInfo":{"status":"ok","timestamp":1741977077911,"user_tz":180,"elapsed":117,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}},"outputId":"4b4ff1ef-3aa8-4793-8914-32ed993e2f58"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["!echo \".ignoreme\" > .gitignore\n","!git init\n","!git add basico-llm.ipynb\n","!git branch -M main\n","!git commit -m \"dados - tokenização - início de transformer\"\n","!git remote add origin https://{token}@github.com/{username}/llm-estudos.txt\n","!git push -u origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inM-WeZt6Dfu","executionInfo":{"status":"ok","timestamp":1741979349075,"user_tz":180,"elapsed":1951,"user":{"displayName":"Gracielle do Nascimento","userId":"00388770392627040803"}},"outputId":"67eb9f8f-25f4-45e5-fa10-91bc7f8aa79e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/drive/MyDrive/Colab Notebooks/.git/\n","Author identity unknown\n","\n","*** Please tell me who you are.\n","\n","Run\n","\n","  git config --global user.email \"you@example.com\"\n","  git config --global user.name \"Your Name\"\n","\n","to set your account's default identity.\n","Omit --global to set the identity only in this repository.\n","\n","fatal: unable to auto-detect email address (got 'root@8d850278189f.(none)')\n","error: src refspec main does not match any\n","\u001b[31merror: failed to push some refs to 'https://github.com/{username}/llm-estudos.txt'\n","\u001b[m"]}]}]}